---
title: "Legacy Data Confounds Modern Genomics Studies"
author: 
- name: Luke Anderson-Trocmé, Rick Farouni
  affiliation:
  - &cruk Department of Human Genetics, McGill University,  Montreal, Canada
date: '`r format(Sys.Date(), "%Y-%B-%d")`'
output:
  html_notebook:
    df_print: paged
    code_folding: show
    toc: yes
    toc_float: 
      collapsed: false
      smooth_scroll: false
---
  

load libraries
```{r, message = FALSE}
library(ggplot2)
library(RColorBrewer)
library(plotly)
library(colorspace)
library(cowplot)
library(data.table)
library(tidyverse)
library(purrr)
library(lfa)

#Directories
DataPath <- '~/Documents/LegacyData/PlottingScripts/ProcessedData/'
figurePath <- '~/Documents/LegacyData/Figures/'
```

##GWAS
```{r}
#Load single population regression results
Reg <- fread(
  paste0(DataPath,
         '1KGP.GenomeWide.Regression_JPT.csv'),
  col.names = c('Chr', 'Pos',
                'Population', 'deviance'),
  colClasses = c('numeric', 'numeric',
                 'character', 'numeric'))

#Compute P values from deviance from null model
Reg$plog10 <- -log10(pchisq(Reg$deviance,
                            df = 1,
                            lower.tail = FALSE))

#split data into sig / not sig for plotting
SigPos <- Reg[which(Reg$plog10 > 6), ]
NotSig <- Reg[which(Reg$plog10 < 6), ]
rm(Reg) #save memory

#save to file
saveRDS(SigPos,
        paste0(DataPath,
               'SigPos.rds'))
#save to file
saveRDS(NotSig,
        paste0(DataPath,
               'NotSig.rds'))
```
##Joint Frequency Spectrum
```{r}
if(!file.exists(paste0(DataPath,
               'jointAF.rds'))){
  
#Load Allele Frequency files
AF.1kGP <- paste0(DataPath,
                  '1kGP_GenomeWide_JPT_1.frq')
JPT <- fread(
  AF.1kGP,
  fill = TRUE,
  col.names = c('Chr', 'Pos', 'N_ALLELES',
                'N_CHR', 'JPT_AF', 'JPT_MAF'))
AF.NAG <- paste0(DataPath,
                 'NAG_GenomeWide.4bed_filtered.freq.frq')
NAG <- fread(
  AF.NAG,
  fill = TRUE,
  col.names = c('Chr', 'Pos', 'N_ALLELES',
                'N_CHR', 'NAG_AF', 'NAG_MAF'))

#merge them together to get joint frequency spectrum
join <- merge(JPT[which(JPT$JPT_AF <= 1),],
              NAG[which(NAG$NAG_AF <= 1),],
              by = c('Chr', 'Pos'), all = TRUE)
join[is.na(join)] <- 0 #missing positions are frequency of 0

#REMOVE  HWE SITES
hwe_1kGP <- paste0(DataPath,
                   '1kGP_GenomeWide.4bed_filtered_sig6.freq.hwe')
JPT_hwe <- fread(hwe_1kGP)
hwe_NAG <- paste0(DataPath,
                  'NAG_GenomeWide.4bed_filtered_sig6.freq.hwe')
NAG_hwe <- fread(hwe_NAG)

hwe <- merge(NAG_hwe[, c('V1', 'V2')],
             JPT_hwe[, c('V1', 'V2')],
             by = c('V1', 'V2'),
             all = TRUE)
#remove sites from AF that don't meet HWE
join <- join[!paste(join$Chr, join$Pos)
             %in% c(paste(hwe$V1, hwe$V2)), ]

join <- join[, c('Chr', 'Pos', 'JPT_MAF', 'NAG_MAF')]
#make numeric
join <- sapply(join, as.numeric)
join <- join[complete.cases(join),]

rm(NAG) #free up memory
rm(JPT)
rm(hwe)

join

#save to file
saveRDS(join,
        paste0(DataPath,
               'jointAF.rds'))
}
```

## Mutation Spectrum enrichment
```{r}
########### JPT 1kGP ###########
#get positions of significant SNPs
sig.pos <- SigPos[,c('Chr','Pos')]
write.table(sig.pos, 
            file=paste0(DataPath,
                        'sig.pos.txt'), 
            col.names = FALSE, 
            row.names = FALSE, 
            quote = FALSE, 
            sep = '\t')

#get positions of random SNPs as control
set.seed(123)
random.pos <- NotSig[sample(nrow(NotSig), 
                            nrow(sig.pos)),
                     c('Chr','Pos')]
write.table(random.pos, 
            file = paste0(DataPath,
                        'random.pos.txt'), 
            col.names = FALSE, 
            row.names = FALSE, 
            quote = FALSE, 
            sep = '\t')
rm(NotSig) #save memory

########### GCAT 1kGP ###########
#see RegressionResults.rmd for Regression

#get positions of random SNPs as control
set.seed(123)

number_of_sig <- 
  nrow(Regression[which(
    Regression$Adjusted_Log10p 
    > -log10(0.01)),])

gcat.random.pos <- 
  Regression[sample(nrow(Regression), 
                    number_of_sig),
             c('Chr','Pos')]

write.table(gcat.random.pos, 
            file = paste0(DataPath,
                        'gcat.random.pos.txt'), 
            col.names = FALSE, 
            row.names = FALSE, 
            quote = FALSE, 
            sep = '\t')

strict_sig <- nrow(RegressionMasked[which(
    RegressionMasked$Adjusted_Log10p 
    > -log10(0.01)),])

strict.gcat.random.pos <- 
  RegressionMasked[sample(nrow(RegressionMasked), 
                    strict_sig),
             c('Chr','Pos')]

write.table(strict.gcat.random.pos, 
            file = paste0(DataPath,
                        'strict.gcat.random.pos.txt'), 
            col.names = FALSE, 
            row.names = FALSE, 
            quote = FALSE, 
            sep = '\t')

strict.gcat.pos <- 
  RegressionMasked[which(
    RegressionMasked$Adjusted_Log10p 
    > -log10(0.01)),
    c('Chr','Pos')]

write.table(strict.gcat.pos, 
            file = paste0(DataPath,
                        'strict.gcat.pos.txt'), 
            col.names = FALSE, 
            row.names = FALSE, 
            quote = FALSE, 
            sep = '\t')

```
extract context for snps of interest
```{bash}
#Using GenomeWide.AncestralContext.txt
#To get mutation context, use $path/AncestralContext.py
#compare first two columns in both files, extract matches
path='/Users/luke/Documents/QualityPaper/Misc/'
if [ ! -f $path/random.pos.context.txt ]; then
  echo "random pos context"
  awk 'NR==FNR{a[$1,$2];next} ($1,$2) in a' \
  $path/random.pos.txt \
  $path/GenomeWide.AncestralContext.txt \
  > $path/random.pos.context.txt
fi  
  
if [ ! -f $path/sig.pos.context.txt ]; then
  echo "sig pos context"
  awk 'NR==FNR{a[$1,$2];next} ($1,$2) in a' \
  $path/sig.pos.txt \
  $path/GenomeWide.AncestralContext.txt \
  > $path/sig.pos.context.txt
fi 
```

extract context for GCAT test snps of interest
```{bash}
#Using GenomeWide.AncestralContext.txt
#To get mutation context, use $path/AncestralContext.py
#compare first two columns in both files, extract matches
out_path='/Users/luke/Documents/LegacyData/LatexManuscript/SupplementaryData/'
path='/Users/luke/Documents/LegacyData/PlottingScripts/ProcessedData/'

if [ ! -f $path/strict.gcat.random.pos.context.txt ]; then
  echo "gcat random pos context"
  awk 'NR==FNR{a[$1,$2];next} ($1,$2) in a' \
  $path/strict.gcat.random.pos.txt \
  $path/GenomeWide.AncestralContext.txt \
  > $path/strict.gcat.random.pos.context.txt
fi  

if [ ! -f $path/strict.gcat.sig.pos.context.txt ]; then
  echo "sig pos context"
  awk 'NR==FNR{a[$1,$2];next} ($1,$2) in a' \
  $path/strict.gcat.pos.txt \
  $path/GenomeWide.AncestralContext.txt \
  > $path/strict.gcat.sig.pos.context.txt
fi 
```

Load mutation context and plot enrichment
```{r}
contextHeader = c('Chr','Pos','Ref','Alt','Flip','Context')

#toggle for all snps or just JPT 1kGP snps
name <-'strict.gcat.' #'gcat.' # '' #

#load SNP context
SNP <- read.table(paste0(DataPath, name,'sig.pos.context.txt'), 
                sep = '\t', 
                header  = FALSE,
                col.names = contextHeader)

rSNP <- read.table(paste0(DataPath,'GenomeWide.AncestralContext.txt'), 
                sep = '\t',
                header = FALSE,
                col.names = contextHeader)

ReverseComp <- function(x)
        chartr("ATGC","TACG",
        sapply(
          lapply(
          strsplit(x, NULL), 
          rev), 
          paste, 
          collapse = ""))

processContext <- function(data){
  
#get reverse complement of context, ref and alt
data$Rev<-ReverseComp(as.character(data$Context))
data$RevRef<-ReverseComp(as.character(data$Ref))
data$RevAlt<-ReverseComp(as.character(data$Alt))
#only get one half (to fold over)
AC<-data[which(data$Ref 
               %in% 
                 c('A','C')),]
TG<-data[which(data$Ref 
               %in% 
                 c('T','G')),]
#fold over
TG$Context <- TG$Rev
TG$Ref <- TG$RevRef
TG$Alt <- TG$RevAlt
#bind them together
data <- rbind(AC,TG)
#combine it all together to get a context
data$Mut <- paste0(data$Ref,'->', 
                substr(data$Context,1,1),
                data$Alt,
                substr(data$Context,3,3))
#get the counts of each bin
binCount <- as.data.frame(table(data$Mut))
#process for plotting
binCount$Start <- substr(binCount$Var1,4,4)
binCount$End <- substr(binCount$Var1,6,6)
binCount$Mut <- paste(substr(binCount$Var1,1,3),
                      substr(binCount$Var1,5,5))
binCount$Mut <- gsub('->', ' →',binCount$Mut)

binCount$Var1 <- NULL

return(binCount)
}


SNP <- processContext(SNP)

rSNP <- processContext(rSNP)
rSNP <- 
  rSNP %>%
  filter(Start != "N" &
           End != "N")
  
#get proportions
total_count <- sum(rSNP$Freq)
total_sample <- sum(SNP$Freq)
rSNP$Freq <- rSNP$Freq / total_count * total_sample



#chi-squared contingency table tests
chi_test <- merge(SNP, rSNP, 
                  by = c('Start','End', 'Mut'), 
                  all =T)

chi_test[is.na(chi_test)] <- 0

chi_test$chi_p <- 
  lapply(split(chi_test %>% 
                 select(Freq.x,Freq.y), 
               (1:nrow(chi_test) - 1)), 
         function(data) 
           chisq.test(data)$p.value)


SNP <- merge(SNP, 
             chi_test %>% 
               select(c('Start','End', 'Mut','chi_p')), 
             by = c('Start','End', 'Mut'))

SNP
#save to file
saveRDS(SNP,
            paste0(DataPath, name,
                   'SNP_Context.rds'))

#save to file
saveRDS(rSNP,
            paste0(DataPath, name,
                   'rSNP_Context.rds'))
```


##Data Quality Over Time
```{r}
BasPath = '/Users/luke/genomes/bas_file/1000GenomesBAS/'

#load bas_dt
#see 1_make_quality_dt.Rmd for making this file
load(paste0(DataPath,'bas_dt'))

#get the index files for extra meta data
#wget http://ftp.1000genomes.ebi.ac.uk/vol1/ftp/phase3/20130502.phase3.analysis.sequence.index
index <- read.table(paste0(BasPath, 
                           '20130502.phase3.analysis.sequence.index'),
               comment.char = "?", 
               fill = TRUE,
               sep = "\t", 
               header = TRUE,
               stringsAsFactors = FALSE)
#keep columns of interest
index <- unique(index[,c('SAMPLE_NAME',
                         'CENTER_NAME',
                         'SUBMISSION_DATE',
                         'INSTRUMENT_MODEL')])

#Phase 1 samples, list downloaded from http://www.internationalgenome.org/data-portal/sample
phase <- read.table(paste0(DataPath,
                           'Phase1_IDs.txt'))
phase$Phase = 1

#merge tables
bas_dt <- merge(bas_dt, 
                index, 
                by.x = "sample", 
                by.y = "SAMPLE_NAME",
                all.x = TRUE)
bas_dt <- merge(bas_dt, 
                phase, 
                by.x = "sample", 
                by.y = "V1", 
                all.x = TRUE)
bas_dt[which(is.na(bas_dt$Phase)),]$Phase <- 3
#clean up the text
bas_dt$SUBMISSION_DATE <- gsub(" 00:00:00",
                               "",
                               bas_dt$SUBMISSION_DATE)
bas_dt$SUBMISSION_DATE <- as.Date(bas_dt$SUBMISSION_DATE, 
                                  "%Y-%m-%d")
bas_dt$CENTER_NAME<-gsub('Illumina',
                         'ILLUMINA',
                         bas_dt$CENTER_NAME)
bas_dt$INSTRUMENT_MODEL <-gsub('Illumina',
                               '',
                               bas_dt$INSTRUMENT_MODEL)
bas_dt$INSTRUMENT_MODEL <-gsub('Genome Analyzer',
                               'GA',
                               bas_dt$INSTRUMENT_MODEL)
bas_dt$INSTRUMENT_MODEL <-gsub('HiSeq 2000',
                               'HS 2k',
                               bas_dt$INSTRUMENT_MODEL)
#remove missing data
bas_dt<-bas_dt[complete.cases(bas_dt),]

#Get the average sequencing date per population
#Used for ranking the populations
Day<-aggregate(bas_dt$SUBMISSION_DATE, 
               list(bas_dt$Population), 
               mean)
#add it to data
metaData<-merge(bas_dt, 
                Day, 
                by.x = 'Population', 
                by.y = 'Group.1')
#reorder data by average date then quality
metaData <- metaData[with(metaData, 
                          order(x,
                                Population, 
                                avg_qual)),]
#set factor with order in mind (for plotting)
metaData$sample <- factor(metaData$sample, 
                          levels = unique(metaData$sample))
rownames(metaData) <- NULL
metaData$order <- rownames(metaData)

metaData
#save to file
saveRDS(metaData,
            paste0(DataPath,
                   'metaData.rds'))
```
##Overlap of Significant SNPs from Single Population test
```{r}
phase1 <- c('YRI','LWK','CHB','CHD','JPT','CEU','LWK')
#read single population regressions
Reg <- fread(paste0(DataPath,
                    'AllRegressionsOver10.txt'), 
             col.names = c('Chr','Pos',
                           'Population','deviance'), 
             colClasses = c('numeric', 'numeric', 
                            'character', 'numeric'))

strictMask <- fread(paste0(DataPath,
                           '1kGP_StrictMask.bed'),
            col.names = c('Chr','Pos','Pos.1','rsID'))
#remove positions that don't pass strict mask
Reg <- anti_join(Reg,
                 strictMask,
                 by = c('Chr','Pos'))

#Get P-Values and significant sites
Reg$plog10 <- -log10(pchisq(Reg$deviance, 1, 
                            lower.tail = FALSE))
Reg<-Reg[which(Reg$plog10 >= 6),]
#Count number of populations where a variant is significant
NumPop <- as.data.frame(table(Reg$Chr,Reg$Pos))
NumPop <- NumPop[which(NumPop$Freq>1),]
names(NumPop) <- c('Chr','Pos', 'SigHits')
NumPop$Chr<-as.numeric(as.character(NumPop$Chr)) 
NumPop$Pos<-as.numeric(as.character(NumPop$Pos))

m <- merge(Reg,
           NumPop, 
           by = c('Chr','Pos'))
#count number of significant sites per population
n <- as.data.frame(table(m$Pop))
#put it all together for plotting
overLap <- unique(merge(m,n,
                        by.x = 'Population',
                        by.y = 'Var1'))
#include number of significant sites in titles
overLap$title = paste0(overLap$Pop,
                       ' : ', 
                       overLap$Freq)
#add asterix for Phase 1 pops
Phase1Title <- paste('*',
                     overLap[which(overLap$Pop 
                                   %in% phase1),]$title)
overLap[which(overLap$Pop
              %in% phase1),]$title <- Phase1Title
#set order by SigHits, Chromosome and Position
overLap <- overLap[with(overLap, 
                        order(-SigHits,
                              Chr,
                              Pos)),]
overLap$Pos <- factor(overLap$Pos, 
                      levels = unique(overLap$Pos))
#this is for keeping track of the number of variants
overLap$nrow <- seq(length = nrow(overLap))
#this is for discrete point size
overLap$Pcat <- 4
overLap[which(overLap$plog10 < 8),]$Pcat <- 2
overLap[which((overLap$plog10 > 8) & 
              (overLap$plog10 < 10)),]$Pcat <- 3


overLap

#save to file
saveRDS(overLap,
            paste0(DataPath,
                   'overLap.rds'))
```


## Compare Han Resequenced to 1kGP
##Single Population Test
```{r}
#load 1kgp 
kgp1= paste0(DataPath,
             '1kGP_genomeWide_SINGLEPOP_83.genotypes.txt')
kgp1.n=fread(paste0(DataPath,
                    '1kGP_genomeWide_SINGLEPOP_83.header'))
gt1<-unique(fread(kgp1,
                  col.names = colnames(kgp1.n)))
gt1.m<-melt(gt1, 
            id.vars = c('#CHROM','POS','ID'))
colnames(gt1.m) = c('CHROM','POS',
                    'ID','sample','kGT')


han1=paste0(DataPath,
            '90_Han_Chinese_SigPos.genotypes.txt')
han1.n=fread(paste0(DataPath,
                    '90_Han_Chinese_SigPos.header'))
gtHan <-unique(fread(han1,
                     col.names = colnames(han1.n)))
gtHan$'#CHROM' <- as.integer(as.character(gsub('chr','',gtHan$'#CHROM')))
gtHan.m<-melt(gtHan, 
              id.vars = c('#CHROM','POS','ID'))
colnames(gtHan.m)=c('CHROM','POS',
                    'ID','sample','HanGT')

#merge
HanKgpAF<-merge(gtHan.m, 
          gt1.m, 
          by = c('CHROM','POS',
                 'ID','sample'), 
          all.y=T)

HanKgpAF[is.na(HanKgpAF)] <- 0

#to get allele frequencies we group by POS and summarize GT
HanKgpAF <- HanKgpAF %>% 
  group_by(CHROM,POS) %>% 
  summarize(hanAF = sum(HanGT), 
            kgpAF = sum(kGT)) 

#remove sites missing in this subset of individuals
HanKgpAF <- HanKgpAF[which(HanKgpAF$kgpAF > 0),]

HanKgpAF

#save to file
saveRDS(HanKgpAF,
            paste0(DataPath,
                   'HanKgpAF.rds'))
```
##Extract Significant Positions from 1kGP Data
```{bash}
DataPath='/Users/luke/Documents/LegacyData/PlottingScripts/ProcessedData'
RawDataPath='/Users/luke/genomes/genomes/hg19/phase3'
VCF='.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz'

#GetHeader
zgrep '^#' $RawDataPath/ALL.chr22$VCF > $DataPath/Significant_Positions.vcf

#AddGenotypes
for f in `seq 1 22`;
do bcftools view \
-R $DataPath/Significant_Positions.txt \
$RawDataPath/ALL.chr${f}$VCF \
| grep -v "^#" \
>> $DataPath/Significant_Positions.vcf ; \
done

#bcftools doesn't take rsID
#this deals with indels and other mulitallelic variants
vcftools \
--vcf $DataPath/Significant_Positions.vcf \
--snps $DataPath/Significant_rsID.txt \
--keep $DataPath/83samples.txt \
--recode --recode-INFO-all \
--out $DataPath/Significant_Positions

/Users/luke/bin/plink_mac/plink \
--vcf $DataPath/Significant_Positions.recode.vcf \
--make-bed \
--out $DataPath/Significant_Positions

#Get Allele Frequencies
/Users/luke/bin/plink_mac/plink \
--bfile $DataPath/Significant_Positions \
--freq \
--out $DataPath/Significant_Positions


#bcftools doesn't take rsID
#this deals with indels and other mulitallelic variants
vcftools \
--vcf $DataPath/Significant_Positions.vcf \
--snps $DataPath/Significant_rsID.txt \
--recode --recode-INFO-all \
--out $DataPath/Significant_Positions_allPop

/Users/luke/bin/plink_mac/plink \
--vcf $DataPath/Significant_Positions_allPop.recode.vcf \
--make-bed \
--out $DataPath/Significant_Positions_allPop

#Get Allele Frequencies
/Users/luke/bin/plink_mac/plink \
--bfile $DataPath/Significant_Positions_allPop \
--freq \
--out $DataPath/Significant_Positions_allPop
```

##Extract Significant Positions from Han Resequence Data
```{bash}
DataPath='/Users/luke/Documents/LegacyData/PlottingScripts/ProcessedData'
RawDataPath='/Users/luke/genomes/genomes/Han90/90_Han_Chinese_SNP_gatkvqsr_20170424_chr'
VCF='_validator.vcf.gz'

#Han vcf has `chr` before chromosome number
sed -e 's/^/chr/' \
$DataPath/Significant_Positions.txt \
> $DataPath/Significant_Positions_chr.txt

#GetHeader
zgrep '^#' $RawDataPath\22$VCF > $DataPath/Significant_Positions_Han.vcf

#AddGenotypes
for f in `seq 1 22`;
do bcftools view \
-R $DataPath/Significant_Positions_chr.txt \
$RawDataPath${f}$VCF \
| grep -v "^#" \
>> $DataPath/Significant_Positions_Han.vcf ; \
done

#bcftools doesn't take rsID
#this deals with indels and other mulitallelic variants
vcftools \
--vcf $DataPath/Significant_Positions_Han.vcf \
--snps $DataPath/Significant_rsID.txt \
--keep $DataPath/83samples.txt \
--recode --recode-INFO-all \
--out $DataPath/Significant_Positions_Han

/Users/luke/bin/plink_mac/plink \
--vcf $DataPath/Significant_Positions_Han.recode.vcf \
--make-bed \
--out $DataPath/Significant_Positions_Han

#Get Allele Frequencies
/Users/luke/bin/plink_mac/plink \
--bfile $DataPath/Significant_Positions_Han \
--freq \
--out $DataPath/Significant_Positions_Han
```

##Compare Over and Under Qual 30
```{r}
data_bim <- fread(paste0(DataPath,
                         'Significant_Positions_allPop.bim'), 
                  col.names = c('Chr','rsID','X',
                                'Pos','Ref','Alt')) %>%
  select(rsID)

data_fam <- fread(paste0(DataPath,
                         'Significant_Positions_allPop.fam'), `
                  col.names = c('familyID','sample',
                                'father','mother',
                                'sex','pheno')) %>%
  select(sample)

data_genotype <- read.bed(paste0(DataPath,'Significant_Positions_allPop'))
rownames(data_genotype) <- data_bim$rsID
colnames(data_genotype) <- data_fam$sample
data_genotype[1:5,1:5]

##Compare over and under 30

mGT = melt(unique(data_genotype), 
           varnames = c('rsID','sample'), 
           value.name = 'Genotype')

mGT = merge(unique(bas_dt[,
                          c('sample',
                            'Population',
                            'avg_qual')]), 
            mGT, 
            by = 'sample')


over30 = unique(mGT[which(mGT$avg_qual > 30),])

under30 = unique(mGT[which(mGT$avg_qual < 30),])

o30AF <- 
		over30 %>% 
		group_by(rsID) %>% 
		summarize(oAF = sum(Genotype))
		
u30AF <- 
		under30 %>% 
		group_by(rsID) %>% 
		summarize(uAF = sum(Genotype))

AF30 <- merge(u30AF, 
              o30AF, 
              by=c('rsID'))

#save to file
saveRDS(AF30,
            paste0(DataPath,
                   'AF30.rds'))
```

##OMNI CHIP
```{r}
omni <- fread(paste0(DataPath,
                     'HumanOmni2-5-8-v1-2-A-b138-rsIDs.txt'),
              header = T)
omni <- merge(omni, 
              plt, 
              by.x='RsID', 
              by.y='rsID')
omni <- omni[which(omni$RsID != '.'),]

#save to file
saveRDS(omni,
            paste0(DataPath,
                   'omni.rds'))
```

##Imputation Scores
```{r}
library(data.table)
library(spatstat)
library(rdist)
library(Rfast)
#Imputation scores for Japanese genotyped individuals
suspicious <- fread('/Users/luke/Documents/LegacyData/LatexManuscript/SupplementaryData/Significant_Positions_and_Pvals.txt')
#set path and array name
jpt_imp_path = "/Users/luke/Documents/Legacy_Misc/Misc/ImputationScores/"
array = "610k" #2500k_2500o #ASA #CoreExome24
#list of filenames
jpt_imp_files = list.files(path=jpt_imp_path, 
                           pattern=paste0(array,".imputed.*.info.gz"),
                           full.names = T) 
# Read the files
jpt_imp <- lapply(jpt_imp_files, 
                  function(x) {fread(paste('gzcat', x), 
                                          header = T, 
                                          sep ="\t")})
# Combine them
jpt_imp <- do.call("rbind", 
                   lapply(jpt_imp, as.data.frame)) 

jpt_imp <- separate(data = jpt_imp, 
                    col = SNP, 
                    into = c("Chr", "Pos"), 
                    sep = ":")


#jpt_imp <- merge(jpt_imp, suspicious, 
#                 by = c('Chr', 'Pos'), all.x = T)

jpt_imp$Pos <- as.numeric(as.character(jpt_imp$Pos))
jpt_imp$Chr <- as.numeric(as.character(jpt_imp$Chr))

jpt_imp
```

```{r}

close_list <- data.frame()
for(chrom in seq(1,22)){
  print(chrom)
  
  imputed_position <- 
    jpt_imp %>% 
    filter(Chr == chrom) %>%
    select(Pos) %>%
    unlist()
  
  suspicious_position <- 
    suspicious %>% 
    filter(Chr == chrom) %>%
    select(Pos) %>%
    unlist()
  
  close <- 
  unlist(lapply(imputed_position, 
                function(x) suspicious_position[which.min(abs(suspicious_position - x))]))
  
  out <- data.frame("Pos" = imputed_position, 
                       "closest" = close)
  rownames(out) <- NULL
  
  close_list <- rbind(close_list, out)
}

close_list
```

```{r}

jpt_imp$dist <- abs(close_list$closest - close_list$Pos)

jpt_imp$dist_2 <- round(jpt_imp$dist, -3)

jpt_imp_sub <- jpt_imp %>%
  select(AvgCall, Rsq, dist_2) %>%
  group_by(dist_2) %>%
  summarise(AvgCall_mean = mean(AvgCall),
            Rsq_mean = mean(Rsq))


#plot distance from nearest suspicious variant 
Rsq <- 
  ggplot(jpt_imp_sub, 
       aes(x= dist_2, 
           y = Rsq_mean)) +
  geom_point() +
  labs(x = "Distance from nearest suspicious variant",
       y = "Rsq") +
  xlim(c(0,5000))

AvgCall <- 
  ggplot(jpt_imp_sub, 
       aes(x= dist_2, 
           y = AvgCall_mean)) +
  geom_point() +
  labs(x = "Distance from nearest suspicious variant",
       y = "Average Call") +
  xlim(c(0,5000))

plot_grid(AvgCall, Rsq, ncol=1)

ggsave(paste0(figurePath,
              "Imputation_Distance_1000s_gw.jpg"),
       height = 9,
       width = 9)
```

```{r}


```



